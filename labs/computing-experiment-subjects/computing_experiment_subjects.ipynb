{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Computing Experiment Datasets #1: Experiment Subjects\n",
        "\n",
        "This Lab is part of a multi-part series focused on computing useful experiment datasets. In this Lab, we'll use [PySpark](https://spark.apache.org/docs/latest/api/python/index.html) to compute _experiment subjects_ from [Optimizely Enriched Event](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-export) [\"ecision\"](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification#decisions-2) data.\n",
        "\n",
        "<!-- We use an external image URL rather than a relative path so that this notebook will be rendered correctly on the Optimizely Labs website -->\n",
        "![Experiment subjects computation](https://raw.githubusercontent.com/optimizely/labs/master/labs/computing-experiment-subjects/img/subjects_computation.png)\n",
        "\n",
        "**Experiment subjects** are the individual units that are exposed to a control or treatment in the course of an online experiment.  In most online experiments, subjects are website visitors or app users. However, depending on your experiment design, treatments may also be applied to individual user sessions, service requests, search queries, etc. \n",
        "\n",
        "In this Lab we'll transform an event-level [\"decision\"](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification#decisions-2) input dataset into a subject-level (typically visitor-level) output dataset.  This output dataset contains a record of who was exposed to our experiment, which treatment they received, and when they first received it.  This dataset is useful for\n",
        "- computing aggregate statistics about your experiment subjects, such as the number of visitors saw each \"variation\" on a given day\n",
        "- joining with other analytics datasets (like [Optimizely Enriched \"conversions\"](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification#conversions-2)) to compute experiment metrics and perform experiment analysis\n",
        "\n",
        "This Lab is generated from a Jupyter Notebook.  Scroll to the bottom of this page for instructions on how to run it on your own machine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis parameters\n",
        "\n",
        "We'll use the following global variables to parameterize our computation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Local Data Storage\n",
        "\n",
        "These parameters specify where this notebook should read and write data. The default location is ./example_data in this notebook's directory. You can point the notebook to another data directory by setting the OPTIMIZELY_DATA_DIR environment variable prior to starting Jupyter Lab, e.g.\n",
        "\n",
        "```sh\n",
        "export OPTIMIZELY_DATA_DIR=~/optimizely_data\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Local data storage locations\n",
        "base_data_dir = os.environ.get(\"OPTIMIZELY_DATA_DIR\", \"./example_data\")\n",
        "decisions_dir = os.path.join(base_data_dir, \"type=decisions\")\n",
        "subjects_output_dir = os.path.join(base_data_dir, \"type=subjects\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subject ID column\n",
        "Used to group event-level records by experiment subject.  It's useful to modify this if you wish use another identifier to denote an individual subject, such as\n",
        "- \"session_id\" if you wish to compute session-level metrics with Optimizely data\n",
        "- A custom ID field, perhaps one found in an the user attributes attached to a decision.\n",
        "\n",
        "Note that if you wish to group by a particular [user attribute](\n",
        "https://docs.developers.optimizely.com/full-stack/docs/pass-in-audience-attributes-python), you'll need to add a step to \n",
        "transform your decision data such that this attribute is exposed in its own column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Subject ID column\n",
        "subject_id = \"visitor_id\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis window\n",
        "The analysis window determines which decisions are included in your analysis.  The default window is this notebook is large enough that *all* decisions loaded will be included in the computation, but you can adjust this to focus on a specific time window.\n",
        "\n",
        "Note that Optimizely Web and Optimizely Full Stack use slightly different attribution logic to determine which subjects are counted in a particular time window.  The logic embedded in the queries in this notebook mimics the Full Stack approach.  More on this below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Analysis window\n",
        "decisions_start = \"2000-01-01 00:00:00\"\n",
        "decisions_end = \"2099-12-31 23:59:59\"\n",
        "\n",
        "# The following are useful for converting timestamps from Optimizely results page URLs into\n",
        "# an analysis window that can be used by the queries in this notebook.\n",
        "# decisions_start = datetime.fromtimestamp(1592416545427 / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
        "# decisions_end = datetime.fromtimestamp(1593108481887 / 1000).strftime('%Y-%m-%d %H:%M:%S')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL\") \\\n",
        "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
        "    .config(\"spark.sql.repl.eagerEval.truncate\", 120) \\\n",
        "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load decision data\n",
        "\n",
        "We'll start by loading decision data and isolating the decisions for the experiment specified by `experiment_id` and the time window specfied by `decisions_start` and `decisions_end`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.read.parquet(decisions_dir).createOrReplaceTempView(\"loaded_decisions\")\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "    CREATE OR REPLACE TEMPORARY VIEW decisions as\n",
        "        SELECT \n",
        "           *\n",
        "        FROM \n",
        "            loaded_decisions\n",
        "        WHERE\n",
        "            timestamp BETWEEN '{decisions_start}' AND '{decisions_end}'\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"SELECT * FROM decisions LIMIT 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute experiment subjects\n",
        "\n",
        "Next we'll group our decision data by `decision_subject_id` in order to produce a table of _experiment subjects_.\n",
        "\n",
        "Experimental subjects are the randomization units used in our experiment. In most cases each subject corresponds to a web/app user, but they may also represent teams, user sessions, requests, etc., depending on the design of your experiment. In this example we use visitors (identified by the `visitor_id` field) as our experiment subjects.\n",
        "\n",
        "This query captures the attribution logic used by [Optimizely Full Stack](https://www.optimizely.com/platform/full-stack/) to isolate the visitors tested in a given experiment:\n",
        "- In order to be counted in the analysis, a visitor must have at least one \"decision\" in the analysis window.\n",
        "- The variation and the timestamp assigned to that visitor correspond to the variation in the _first_ decision received from that visitor during the analysis window\n",
        "\n",
        "**Note:** the visitor counting logic used in [Optimizely Web](https://www.optimizely.com/platform/experimentation/) experiments is slightly different.  See [this article](https://help.optimizely.com/Analyze_Results/How_Optimizely_counts_conversions) for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"\"\"\n",
        "    CREATE OR REPLACE TEMPORARY VIEW experiment_subjects AS\n",
        "        SELECT\n",
        "            {subject_id},\n",
        "            experiment_id,\n",
        "            variation_id,\n",
        "            timestamp\n",
        "        FROM (\n",
        "            SELECT\n",
        "                *,\n",
        "                RANK() OVER (PARTITION BY experiment_id, {subject_id} ORDER BY timestamp ASC) AS rnk\n",
        "            FROM\n",
        "                decisions\n",
        "        )\n",
        "        WHERE\n",
        "            rnk = 1\n",
        "        ORDER BY timestamp ASC\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"\"\"SELECT * FROM experiment_subjects LIMIT 5\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Writing our subjects dataset to disk\n",
        "\n",
        "We'll store our experiment subjects in the directory specified by `subjects_output_dir`.  Subject data is partitioned into directories for each experiment included in the input decision data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"SELECT * FROM experiment_subjects\"\"\") \\\n",
        "    .coalesce(1) \\\n",
        "    .write.mode('overwrite') \\\n",
        "    .partitionBy(\"experiment_id\") \\\n",
        "    .parquet(subjects_output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyzing our subject data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can group by `experiment_id` and `variation_id` to count the number of subjects attributed to each variation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT \n",
        "        experiment_id, \n",
        "        variation_id, \n",
        "        COUNT(1) as subject_count \n",
        "    FROM \n",
        "        experiment_subjects \n",
        "    GROUP BY \n",
        "        experiment_id,\n",
        "        variation_id\n",
        "    ORDER BY\n",
        "        experiment_id,\n",
        "        variation_id\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this Lab we transformed an event-level [\"decision\"](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification#decisions-2) input dataset into a subject-level (typically visitor-level) output dataset.  This output dataset contains a record of who was exposed to our experiment, which treatment they received, and when they first received it. \n",
        "\n",
        "We've written our output dataset to disk so that it can be used in other analyses (and future installments in the Experiment Datasets Lab series.)  We performed a simple aggregation on our subjects dataset: counting the number of visitors in each variation included in our input dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to run this notebook\n",
        "\n",
        "This notebook lives in the [Optimizely Labs](http://github.com/optimizely/labs) repository.  You can download it and everything you need to run it by doing one of the following\n",
        "- Downloading a zipped copy of this Lab directory on the [Optimizely Labs page](https://www.optimizely.com/labs/computing-experiment-subjects/)\n",
        "- Downloading a [zipped copy of the Optimizely Labs repository](https://github.com/optimizely/labs/archive/master.zip) from Github\n",
        "- Cloning the [Github respository](http://github.com/optimizely/labs)\n",
        "\n",
        "Once you've downloaded this Lab directory (on its own, or as part of the [Optimizely Labs](http://github.com/optimizely/labs) repository), follow the instructions in the `README.md` file for this Lab."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "optimizelylabs",
      "language": "python",
      "display_name": "Python 3 (Optimizely Labs)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
