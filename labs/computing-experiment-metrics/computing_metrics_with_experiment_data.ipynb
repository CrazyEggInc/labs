{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Computing metrics with event-level experiment data\n",
        "\n",
        "In this Lab, we'll walk through an end-to-end workflow for computing a series of metrics with data collected by both Optimizely and a third party during an Optimizely Full Stack experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The experiment\n",
        "\n",
        "We'll use simulated data from the following \"experiment\" in this notebook: \n",
        "\n",
        "Attic & Button, a popular imaginary retailer of camera equipment and general electronics, has seen increased shipping times for some of its orders due to logistical difficulties imposed by the COVID-19 pandemic. As a result, customer support call volumes have increased.  In order to inform potential customers and cut down on customer support costs, the company's leadership has decided to add an informative banner to the [atticandbutton.com](http://atticandbutton.com) homepage.\n",
        "\n",
        "In order to measure the impact this banner has on customer support volumes and decide which banner message is most effective, the team at Attic & Button have decided to run an experiment with the following variations:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <img src=\"img/control.png\" alt=\"Control\" style=\"width:100%; padding-left:0px\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src=\"img/message_1.png\" alt=\"Message #1\" style=\"width:100%; padding-right:0px\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src=\"img/message_2.png\" alt=\"Message #2\" style=\"width:100%; padding-right:0px\">\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td style=\"background-color:white; text-align:center\">\n",
        "            \"control\"\n",
        "        </td>\n",
        "        <td style=\"background-color:white; text-align:center\">\n",
        "            \"message_1\"\n",
        "        </td>\n",
        "        <td style=\"background-color:white; text-align:center\">\n",
        "            \"message_2\"\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The challenge\n",
        "\n",
        "Attic & Button's call centers are managed by a third party.  This third party shares call data with Attic & Button periodically in a [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) file, making it difficult to track customer support metrics on Optimizely's [Experiment Results Page](https://app.optimizely.com/l/QQbfVyRFQYGq-J57P-3XoQ?previousView=VARIATIONS&variation=email_button&utm_campaign=copy).\n",
        "\n",
        "In this notebook, we'll use Optimizely Enriched Event Data and our third-party call data to compute a variety of metrics for our experiment, including \"Support calls per visitor\" and \"Total call duration per visitor\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Global parameters\n",
        "\n",
        "The following global parameters are used to control the execution in this notebook.  These parameters may be overridden by setting environment variables prior to launching the notebook, for example:\n",
        "\n",
        "```sh\n",
        "export OPTIMIZELY_DATA_DIR=~/my_analysis_dir\n",
        "```\n",
        "\n",
        "In this block we check whether these parameters have been passed with environment variables and assign default values otherwise.  The default value for `OPTIMIZELY_API_TOKEN` is a read-only token for a demonstration Optimizely project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# This notebook requires an Optimizely API token.\n",
        "# The default token provided here is a read-only token associated with a demo Optimizely account\n",
        "OPTIMIZELY_API_TOKEN = os.environ.get(\"OPTIMIZELY_API_TOKEN\", \"2:d6K8bPrDoTr_x4hiFCNVidcZk0YEPwcIHZk-IZb5sM3Q7RxRDafI\")\n",
        "\n",
        "# Uncomment the following block to enable manual API token entry\n",
        "# if OPTIMIZELY_API_TOKEN is None:\n",
        "#    OPTIMIZELY_API_TOKEN = getpass(\"Enter your Optimizely personal API access token:\")\n",
        "\n",
        "# Default path for reading and writing analysis data\n",
        "OPTIMIZELY_DATA_DIR = os.environ.get(\"OPTIMIZELY_DATA_DIR\", \"./covid_test_data\")\n",
        "\n",
        "# Set environment variables\n",
        "# These variables are used by other notebooks and shell scripts invoked\n",
        "# in this notebook\n",
        "%env OPTIMIZELY_DATA_DIR={OPTIMIZELY_DATA_DIR}\n",
        "%env OPTIMIZELY_API_TOKEN={OPTIMIZELY_API_TOKEN}\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Optimizely Enriched Event data\n",
        "\n",
        "This notebook relies (in part) on data downloaded from Optimizely's [Enriched Event Export Service](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-export).\n",
        "\n",
        "The default input data for this notebook can be found in the in `covid_test_data` directory.  \n",
        "\n",
        "If you have the [oevents](https://github.com/optimizely/oevents) command line tool installed and accessible in your`PATH` environment variable, you may uncomment the following commands to re-download this data. Note that this will require `OPTIMIZELY_API_TOKEN` to be set to the default value specified above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll start by downloading [decision](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification#decisions-2) data collected during our experiment.  Each **decision** captures the moment a visitor was added to our experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment this line to re-download decision data for this experiment \n",
        "# Note: requires oevents to be install and accessible on your path\n",
        "\n",
        "# !oevents load --type decisions --experiment 18786493712 --date 2020-09-14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we'll download [conversion](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification#conversions-2) data collected during our experiment.  Each **conversion event** captures the moment a visitor took some action on our website, e.g. viewing our homepage, adding an item to their shopping cart, or making a purchase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment this line to re-download conversion data for this experiment \n",
        "# Note: requires oevents to be install and accessible on your path\n",
        "\n",
        "# !oevents load --type events --date 2020-09-14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Decision and Conversion Data into Spark Dataframes\n",
        "\n",
        "We'll use [PySpark](https://spark.apache.org/docs/latest/api/python/index.html) to transform data in this notebook. We'll start by creating a new local Spark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "num_cores = 1\n",
        "driver_ip = \"127.0.0.1\"\n",
        "driver_memory_gb = 1\n",
        "executor_memory_gb = 2\n",
        "\n",
        "# Create a local Spark session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL\") \\\n",
        "    .config(f\"local[{num_cores}]\") \\\n",
        "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
        "    .config(\"spark.sql.repl.eagerEval.truncate\", 120) \\\n",
        "    .config(\"spark.driver.bindAddress\", driver_ip) \\\n",
        "    .config(\"spark.driver.host\", driver_ip) \\\n",
        "    .config(\"spark.driver.memory\", f\"{driver_memory_gb}g\") \\\n",
        "    .config(\"spark.executor.memory\", f\"{executor_memory_gb}g\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we'll load our decision data into a Spark dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from lib import util\n",
        "\n",
        "decisions_dir = os.path.join(OPTIMIZELY_DATA_DIR, \"type=decisions\")\n",
        "\n",
        "# load enriched decision data from disk into a new Spark dataframe\n",
        "decisions = util.read_parquet_data_from_disk(\n",
        "    spark_session=spark,\n",
        "    data_path=decisions_dir,\n",
        "    view_name=\"decisions\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can write SQL-style queries against our `enriched_decisions` view.  Let's use a simple query to examine our data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM\n",
        "        decisions\n",
        "    LIMIT 3\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we'll load conversion data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# oevents downloads conversion data into the type=events subdirectory\n",
        "conversions_dir = os.path.join(OPTIMIZELY_DATA_DIR, \"type=events\")\n",
        "\n",
        "# load conversion data from disk into a new Spark dataframe\n",
        "converions = util.read_parquet_data_from_disk(\n",
        "    spark_session=spark,\n",
        "    data_path=conversions_dir,\n",
        "    view_name=\"events\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look at our data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM\n",
        "        events\n",
        "    LIMIT 3\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute some useful intermediate experiment datasets\n",
        "\n",
        "In this section, we'll compute three useful intermediate experiment datasets:\n",
        "\n",
        "1. Enriched decisions - Optimizely [decision](https://docs.developers.optimizely.com/optimizely-data/docs/enriched-events-data-specification#decisions-2) data enriched with human-readable experiment and variation names.\n",
        "2. Experiment Units - the individual units (usually website visitors or app users) that are exposed to a control or treatment in the course of a digital experiment.\n",
        "3. Experiment Events - conversion events, such as a button click or a purchase, that were influenced by a digital experiment.\n",
        "\n",
        "The following diagram illustrates how these datasets are used to compute _metric observations_ for our experiment:\n",
        "\n",
        "![Transformations](img/transformations.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Enriched decisions\n",
        "\n",
        "First we'll use Optimizely's [Experiment API](https://library.optimizely.com/docs/api/app/v2/index.html#operation/get_experiment) to enrich our decision data with experiment and variation names.  This step makes it easier to build human-readable experiment reports with this data.\n",
        "\n",
        "The code for enriching decision data can be found in the `enriching_decision_data.ipynb` notebook in this lab directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run ./enriching_decision_data.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment Units\n",
        "\n",
        "**Experiment units** are the individual units that are exposed to a control or treatment in the course of an online experiment.  In most online experiments, subjects are website visitors or app users. However, depending on your experiment design, treatments may also be applied to individual user sessions, service requests, search queries, etc. \n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <img src=\"img/transformations_1.png\" alt=\"Experiment Units\" style=\"width:100%; padding-left:0px\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src=\"img/tables_1.png\" alt=\"Experiment Units\" style=\"width:100%; padding-left:0px\">\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_units = spark.sql(f\"\"\"\n",
        "    SELECT\n",
        "        *\n",
        "    FROM (\n",
        "        SELECT\n",
        "            *,\n",
        "            RANK() OVER (PARTITION BY experiment_id, visitor_id ORDER BY timestamp ASC) AS rnk\n",
        "        FROM\n",
        "            enriched_decisions\n",
        "    )\n",
        "    WHERE\n",
        "        rnk = 1\n",
        "    ORDER BY timestamp ASC\n",
        "\"\"\").drop(\"rnk\")\n",
        "experiment_units.createOrReplaceTempView(\"experiment_units\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine our experiment unit dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        visitor_id,\n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        timestamp\n",
        "    FROM\n",
        "        experiment_units\n",
        "    LIMIT 3\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's count the number of visitors in each experiment variation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT \n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        count(*) as unit_count\n",
        "    FROM \n",
        "        experiment_units\n",
        "    GROUP BY \n",
        "        experiment_name,\n",
        "        variation_name\n",
        "    ORDER BY\n",
        "        experiment_name ASC,\n",
        "        variation_name ASC\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment Events\n",
        "\n",
        "An **experiment event** is an event, such as a button click or a purchase, that was influenced by an experiment.  We compute this view by isolating the conversion events triggered during a finite window of time (called the _attribution window_) after a visitor has been exposed to an experiment treatment.\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <img src=\"img/transformations_2.png\" alt=\"Experiment Units\" style=\"width:100%; padding-left:0px\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src=\"img/tables_2.png\" alt=\"Experiment Units\" style=\"width:100%; padding-left:0px\">\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the experiment_events view\n",
        "experiment_events = spark.sql(f\"\"\"\n",
        "    SELECT\n",
        "        u.experiment_id,\n",
        "        u.experiment_name,\n",
        "        u.variation_id,\n",
        "        u.variation_name,\n",
        "        e.*\n",
        "    FROM\n",
        "        experiment_units u INNER JOIN events e ON u.visitor_id = e.visitor_id\n",
        "    WHERE\n",
        "        e.timestamp BETWEEN u.timestamp AND (u.timestamp + INTERVAL 48 HOURS)\n",
        "\"\"\")\n",
        "experiment_events.createOrReplaceTempView(\"experiment_events\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine our Experiment Events dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        timestamp,\n",
        "        visitor_id,\n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        event_name,\n",
        "        tags,\n",
        "        revenue\n",
        "    FROM\n",
        "        experiment_events\n",
        "    LIMIT 10\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As above, let's count the number of events that were influenced by each variation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"\"\"\n",
        "    SELECT\n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        event_name,\n",
        "        count(*) as event_count\n",
        "    FROM\n",
        "        experiment_events\n",
        "    GROUP BY\n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        event_name\n",
        "    ORDER BY\n",
        "        experiment_name ASC,\n",
        "        variation_name ASC,\n",
        "        event_name ASC\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute metric observations\n",
        "\n",
        "**Metric observations** map each **experiment unit** to a specific numerical outcome observed during an experiment.  For example, in order to measure purchase conversion rate associated with each variation in an experiment, we can map each visitor to a 0 or 1, depending on whether or not they'd made at least one purchase during the attribution window in our experiment.\n",
        "\n",
        "Unlike **experiment units** and **experiment events**, which can be computed using simple transformations,  **metric observations** are metric-dependent and can be arbitrarily complex, depending on the outcome you're trying to measure.\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <img src=\"img/transformations_3.png\" alt=\"Experiment Units\" style=\"width:100%; padding-left:0px\">\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src=\"img/tables_3.png\" alt=\"Experiment Units\" style=\"width:100%; padding-left:0px\">\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We're going to use a helper function, `compute_metric_observations`, to abstract away some of the redundant parts of this computation.  This function takes a set of \"raw observations\" as input, and\n",
        "\n",
        "1. performs a `LEFT JOIN` with our experiment units in order to ensure that the resulting dataset contains an observation for every visitor in our experiment\n",
        "2. (optionally) appends the resulting metric observations to a global `observations` dataset\n",
        "\n",
        "This allows us to focus on the logic for aggregating experiment events into a numerical observation, which is the most interesting part of the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metric: Purchase conversion rate\n",
        "\n",
        "In this query we measure for each visitor whether they made _at least one_ purchase. The resulting observation should be `1` if the visitor triggered the event in question during the _attribution window_ and `0` otherwise.  \n",
        "\n",
        "Since _any_ visitor who triggered an appropriate experiment event should be counted, we can simply select a `1`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Unique conversions on the \"purchase\" event.\n",
        "raw_purchase_conversion_rate_obs = spark.sql(f\"\"\"\n",
        "    SELECT\n",
        "        visitor_id,\n",
        "        1 as observation\n",
        "    FROM\n",
        "        experiment_events\n",
        "    WHERE\n",
        "        event_name = 'purchase'\n",
        "    GROUP BY\n",
        "        visitor_id\n",
        "\"\"\")\n",
        "raw_purchase_conversion_rate_obs.toPandas().head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll use `util.compute_metric_observations` function to perform a left outer join between `experiment_units` and our newly-computed `purchase` conversion data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "observations = util.compute_metric_observations(\n",
        "    \"Purchase conversion rate\",\n",
        "    raw_purchase_conversion_rate_obs,\n",
        "    experiment_units,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look at our observations view:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "observations.createOrReplaceTempView(\"observations\")\n",
        "spark.sql(\"\"\"\n",
        "    SELECT \n",
        "        metric_name,\n",
        "        timestamp,\n",
        "        visitor_id, \n",
        "        experiment_name, \n",
        "        variation_name, \n",
        "        observation \n",
        "    FROM \n",
        "        observations\n",
        "    ORDER BY\n",
        "        timestamp ASC\n",
        "    LIMIT 10\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Metric observations can be used to compute a variety of useful statistics.  Let's compute the value of our `purchase` conversion rate metric for all of the visitors in our experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        metric_name,\n",
        "        experiment_name,\n",
        "        count(1) as unit_count,\n",
        "        sum(observation),\n",
        "        sum(observation) / (1.0 * count(1)) as metric_value\n",
        "    FROM\n",
        "        observations\n",
        "    WHERE\n",
        "        metric_name = \"Purchase conversion rate\"\n",
        "    GROUP BY\n",
        "        metric_name,\n",
        "        experiment_name\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's compute the `purchase` conversion rate broken down by experiment variation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        metric_name,\n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        count(1) as unit_count,\n",
        "        sum(observation),\n",
        "        sum(observation) / (1.0 * count(1)) as metric_value\n",
        "    FROM\n",
        "        observations\n",
        "    WHERE\n",
        "        metric_name = \"Purchase conversion rate\"\n",
        "    GROUP BY\n",
        "        metric_name,\n",
        "        experiment_name,\n",
        "        variation_name\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metric: Product detail page views per visitor\n",
        "\n",
        "In this query we count the number of product detail page views per visitor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Unique conversions on the \"add_to_cart\" event.\n",
        "observations = util.compute_metric_observations(\n",
        "    \"Product detail page views per visitor\",\n",
        "    raw_observations_df = spark.sql(\"\"\"\n",
        "        SELECT\n",
        "            visitor_id,\n",
        "            count(1) as observation\n",
        "        FROM\n",
        "            experiment_events\n",
        "        WHERE\n",
        "            event_name = \"detail_page_view\"\n",
        "        GROUP BY\n",
        "            visitor_id\n",
        "    \"\"\"),\n",
        "    experiment_units_df = experiment_units,\n",
        "    append_to=observations\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can inspect our observations by counting the units and summing up the observations we've computed for each experiment in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT \n",
        "        metric_name, \n",
        "        timestamp,\n",
        "        experiment_name, \n",
        "        variation_id, \n",
        "        visitor_id, \n",
        "        observation \n",
        "    FROM \n",
        "        observations\n",
        "    WHERE\n",
        "        metric_name = \"Product detail page views per visitor\"\n",
        "    LIMIT 5\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metric: Revenue from electronics purchases\n",
        "\n",
        "In this query we compute the total revenue associated with electronics purchases made by our experiment subjects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "observations = util.compute_metric_observations(\n",
        "    \"Electronics revenue per visitor\",\n",
        "    raw_observations_df = spark.sql(\"\"\"\n",
        "        SELECT\n",
        "            visitor_id,\n",
        "            sum(revenue) as observation\n",
        "        FROM \n",
        "            experiment_events\n",
        "            LATERAL VIEW explode(tags) t\n",
        "        WHERE\n",
        "            t.key = \"category\" AND \n",
        "            t.value = \"electronics\" AND\n",
        "            event_name = \"purchase\"\n",
        "        GROUP BY\n",
        "            visitor_id\n",
        "    \"\"\"),\n",
        "    experiment_units_df = experiment_units,\n",
        "    append_to=observations\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, let's examine our observations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT \n",
        "        metric_name, \n",
        "        timestamp,\n",
        "        experiment_name, \n",
        "        variation_id, \n",
        "        visitor_id, \n",
        "        observation \n",
        "    FROM \n",
        "        observations\n",
        "    WHERE\n",
        "        metric_name = \"Electronics revenue per visitor\" AND\n",
        "        observation > 0\n",
        "    LIMIT 5\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metric: Call center volume\n",
        "\n",
        "We can use the same techniques to compute experiment metric using \"external\" data not collected by Optimizely.  We'll demonstrate by loading a CSV customer support call records.\n",
        "\n",
        "We'll start by reading in our call center data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read call center logs CSV into a pandas dataframe\n",
        "df = pd.read_csv(\"covid_test_data/call_data.csv\")\n",
        "\n",
        "# Display a sample of our call record data\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's make sure our call center data schema is compatible with the transformations we want to perform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert \"call start\" timestamp strings to datetime objects\n",
        "df[\"timestamp\"] = pd.to_datetime(df.call_start)\n",
        "\n",
        "# Rename the \"user_id\" column to \"visitor_id\" to match our decision schema\n",
        "df = df.rename(columns={\"user_id\" : \"visitor_id\"})\n",
        "\n",
        "# Convert pandas to spark dataframe\n",
        "call_records = spark.createDataFrame(df)\n",
        "\n",
        "# Create a temporary view so that we can query using SQL\n",
        "call_records.createOrReplaceTempView(\"call_records\")\n",
        "\n",
        "# Display a sample of our call record data\n",
        "spark.sql(\"SELECT * FROM call_records LIMIT 5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's transform our call center logs into \"experiment calls\" using the attribution logic we used above to compute \"experiment events\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the experiment_calls view\n",
        "experiment_calls = spark.sql(f\"\"\"\n",
        "    SELECT\n",
        "        u.experiment_id,\n",
        "        u.experiment_name,\n",
        "        u.variation_id,\n",
        "        u.variation_name,\n",
        "        e.*\n",
        "    FROM\n",
        "        experiment_units u INNER JOIN call_records e ON u.visitor_id = e.visitor_id\n",
        "    WHERE\n",
        "        e.timestamp BETWEEN u.timestamp AND (u.timestamp + INTERVAL 48 HOURS)\n",
        "\"\"\")\n",
        "experiment_calls.createOrReplaceTempView(\"experiment_calls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can compute metric observations for call center calls and duration!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count the number of support phone calls per visitor\n",
        "observations = util.compute_metric_observations(\n",
        "    \"Customer support calls per visitor\",\n",
        "    raw_observations_df = spark.sql(\"\"\"\n",
        "        SELECT\n",
        "            visitor_id,\n",
        "            count(1) as observation\n",
        "        FROM \n",
        "            experiment_calls\n",
        "        GROUP BY\n",
        "            visitor_id\n",
        "    \"\"\"),\n",
        "    experiment_units_df = experiment_units,\n",
        "    append_to=observations\n",
        ")\n",
        "\n",
        "# Count the number of support phone calls per visitor\n",
        "observations = util.compute_metric_observations(\n",
        "    \"Total customer support minutes per visitor\",\n",
        "    raw_observations_df = spark.sql(\"\"\"\n",
        "        SELECT\n",
        "            visitor_id,\n",
        "            sum(call_duration_min) as observation\n",
        "        FROM \n",
        "            experiment_calls\n",
        "        GROUP BY\n",
        "            visitor_id\n",
        "    \"\"\"),\n",
        "    experiment_units_df = experiment_units,\n",
        "    append_to=observations\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing metric values for experiment cohorts\n",
        "\n",
        "We can slice and dice our metric observation data to compute metric values for different experiment cohorts.  Here are some examples:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing metric values per variation\n",
        "\n",
        "Let's start by computing metric values broken down by experiment variation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute metric values broken down by experiment variation\n",
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        metric_name,\n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        count(1) as unit_count,\n",
        "        sum(observation),\n",
        "        sum(observation) / (1.0 * count(1)) as metric_value\n",
        "    FROM\n",
        "        observations\n",
        "    GROUP BY\n",
        "        metric_name,\n",
        "        experiment_name,\n",
        "        variation_name\n",
        "    ORDER BY\n",
        "        metric_name,\n",
        "        experiment_name,\n",
        "        variation_name\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks like the average number of customer support calls per visitor and the average call duration are both much lower in the cohorts that saw one of our informational banner!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing metric values for a visitor segment\n",
        "\n",
        "We can filter metric observations by visitor attributes in order to compute metric values for a particular segment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute metric values broken down by customer segment\n",
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        metric_name,\n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        attrs.value as browser,\n",
        "        count(1) as unit_count,\n",
        "        sum(observation),\n",
        "        sum(observation) / (1.0 * count(1)) as metric_value\n",
        "    FROM\n",
        "        observations\n",
        "        LATERAL VIEW explode(attributes) AS attrs\n",
        "    WHERE\n",
        "        attrs.name = \"browser\"\n",
        "    GROUP BY\n",
        "        metric_name,\n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        attrs.value\n",
        "    ORDER BY\n",
        "        metric_name,\n",
        "        experiment_name,\n",
        "        variation_name,\n",
        "        attrs.value\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing sequential statistics with Optimizely's Stats Services\n",
        "\n",
        "According to the metric data above, visitors who saw either of our informational banners during our experiment were less likely call support.  How confident can we be that the difference in call rates can be attributed to our banner, as opposed to statistical noise?\n",
        "\n",
        "We're working on launching a set of Stats Services that can be used to perform sequential hypothesis testing on metric observation data.  You can learn more about these services and request early access [here](optimizely.com/solutions/data-teams)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Writing our datasets to disk\n",
        "\n",
        "We'll write our experiment units, experiment events, and metric observations datasets to disk so that they may be used for other analysis tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lib import util\n",
        "\n",
        "experiment_units_dir = os.path.join(OPTIMIZELY_DATA_DIR, \"type=experiment_units\")\n",
        "util.write_parquet_data_to_disk(experiment_units, experiment_units_dir, partition_by=\"experiment_id\")\n",
        "\n",
        "experiment_events_dir = os.path.join(OPTIMIZELY_DATA_DIR, \"type=experiment_events\")\n",
        "util.write_parquet_data_to_disk(experiment_events, experiment_events_dir, partition_by=[\"experiment_id\", \"event_name\"])\n",
        "\n",
        "metric_observations_dir = os.path.join(OPTIMIZELY_DATA_DIR, \"type=metric_observations\")\n",
        "util.write_parquet_data_to_disk(observations, metric_observations_dir, partition_by=[\"experiment_id\", \"metric_name\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to run this notebook\n",
        "\n",
        "This notebook lives in the [Optimizely Labs](http://github.com/optimizely/labs) repository.  You can download it and everything you need to run it by doing one of the following\n",
        "- Downloading a zipped copy of this Lab directory on the [Optimizely Labs page](https://www.optimizely.com/labs/computing-experiment-subjects/)\n",
        "- Downloading a [zipped copy of the Optimizely Labs repository](https://github.com/optimizely/labs/archive/master.zip) from Github\n",
        "- Cloning the [Github respository](http://github.com/optimizely/labs)\n",
        "\n",
        "Once you've downloaded this Lab directory (on its own, or as part of the [Optimizely Labs](http://github.com/optimizely/labs) repository), follow the instructions in the `README.md` file for this Lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "optimizelylabs",
      "language": "python",
      "display_name": "Python 3 (Optimizely Labs)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
