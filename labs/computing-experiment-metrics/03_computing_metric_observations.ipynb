{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Experiment Datasets #3: Computing Metric Observations\n",
    "\n",
    "This notebook is part of a multi-part series focused on computing useful experiment datasets. In this notegbook, we'll use [PySpark](https://spark.apache.org/docs/latest/api/python/index.html) to compute a set of numerical measurements for each _unit_ represented in our experiment data.\n",
    "\n",
    "**Metric observations** map each **experiment unit** to a specific numerical outcome observed during an experiment.  For example, in order to measure the purchase conversion rate associated with each variation in an experiment, we can map each visitor to a 0 or a 1, depending on whether or not they made at least one purchase during the attribution window in our experiment.\n",
    "\n",
    "The transformations executed in this notebook are part of a larger [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph) that can be used to perform sequential hypothesis testing with event-level experiment data:\n",
    "\n",
    "![Experiment Analysis DAG](img/transformations.png)\n",
    "\n",
    "This notebook is _experiment agnostic_ and can be used to compute to metric observations with input data collected in any digital experiment.\n",
    "\n",
    "However, this notebook computes a specific set of metrics and expects certain conversion event types to be included in the input dataset.  Therefore, this notebook is probably most useful as an illustration and may also serve as a useful starting point if you want to compute metric observations on your own experiment data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters\n",
    "\n",
    "The following global parameters are used to control the execution in this notebook.  These parameters may be overridden by setting environment variables prior to launching the notebook, e.g.:\n",
    "\n",
    "```\n",
    "export OPTIMIZELY_DATA_DIR=~/my_analysis_dir\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Determines whether output data should be written back to disk\n",
    "# Defaults to False; setting this to True may be useful when running this notebook\n",
    "# as part of a larger workflow\n",
    "SKIP_WRITING_OUTPUT_DATA_TO_DISK = os.environ.get(\"SKIP_WRITING_OUTPUT_DATA_TO_DISK\", False)\n",
    "\n",
    "# Default path for reading and writing analysis data\n",
    "OPTIMIZELY_DATA_DIR = os.environ.get(\"OPTIMIZELY_DATA_DIR\", \"./covid_test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Experiment Unit and Event Data into Spark Dataframes\n",
    "\n",
    "We'll use [PySpark](https://spark.apache.org/docs/latest/api/python/index.html) to transform data in this notebook. We'll start by creating a new local Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "num_cores = 1\n",
    "driver_ip = \"127.0.0.1\"\n",
    "driver_memory_gb = 1\n",
    "executor_memory_gb = 2\n",
    "\n",
    "# Create a local Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL\") \\\n",
    "    .config(f\"local[{num_cores}]\") \\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
    "    .config(\"spark.sql.repl.eagerEval.truncate\", 120) \\\n",
    "    .config(\"spark.driver.bindAddress\", driver_ip) \\\n",
    "    .config(\"spark.driver.host\", driver_ip) \\\n",
    "    .config(\"spark.driver.memory\", f\"{driver_memory_gb}g\") \\\n",
    "    .config(\"spark.executor.memory\", f\"{executor_memory_gb}g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll load our experiment units data into a Spark dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>experiment_name</th><th>variation_name</th><th>reference_variation_id</th><th>uuid</th><th>timestamp</th><th>process_timestamp</th><th>visitor_id</th><th>session_id</th><th>account_id</th><th>campaign_id</th><th>experiment_id</th><th>variation_id</th><th>attributes</th><th>user_ip</th><th>user_agent</th><th>referer</th><th>is_holdback</th><th>revision</th><th>client_engine</th><th>client_version</th><th>date</th><th>experiment</th></tr>\n",
       "<tr><td>covid_messaging_experiment</td><td>control</td><td>18802093142</td><td>3e1d31a3-41c2-4f22-9b77-6a67f44a269a</td><td>2020-09-14 11:21:40.177</td><td>2020-09-14 11:22:05.571</td><td>user_0</td><td>-535397001</td><td>596780373</td><td>18811053836</td><td>18786493712</td><td>18802093142</td><td>[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...</td><td>162.227.140.251</td><td>python-requests/2.24.0</td><td>null</td><td>false</td><td>99</td><td>python-sdk</td><td>3.5.2</td><td>2020-09-14</td><td>18786493712</td></tr>\n",
       "<tr><td>covid_messaging_experiment</td><td>control</td><td>18802093142</td><td>e37700df-856c-46c9-9c6d-b771ff244c2c</td><td>2020-09-14 11:21:40.279</td><td>2020-09-14 11:22:12.287</td><td>user_1</td><td>-1393366513</td><td>596780373</td><td>18811053836</td><td>18786493712</td><td>18802093142</td><td>[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...</td><td>162.227.140.251</td><td>python-requests/2.24.0</td><td>null</td><td>false</td><td>99</td><td>python-sdk</td><td>3.5.2</td><td>2020-09-14</td><td>18786493712</td></tr>\n",
       "<tr><td>covid_messaging_experiment</td><td>control</td><td>18802093142</td><td>c011276d-7ae0-46bd-acfb-28cdcc268545</td><td>2020-09-14 11:21:40.381</td><td>2020-09-14 11:21:59.163</td><td>user_2</td><td>340330538</td><td>596780373</td><td>18811053836</td><td>18786493712</td><td>18802093142</td><td>[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...</td><td>162.227.140.251</td><td>python-requests/2.24.0</td><td>null</td><td>false</td><td>99</td><td>python-sdk</td><td>3.5.2</td><td>2020-09-14</td><td>18786493712</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------------+--------------+----------------------+------------------------------------+-----------------------+-----------------------+----------+-----------+----------+-----------+-------------+------------+------------------------------------------------------------------------------------------------------------------------+---------------+----------------------+-------+-----------+--------+-------------+--------------+----------+-----------+\n",
       "|           experiment_name|variation_name|reference_variation_id|                                uuid|              timestamp|      process_timestamp|visitor_id| session_id|account_id|campaign_id|experiment_id|variation_id|                                                                                                              attributes|        user_ip|            user_agent|referer|is_holdback|revision|client_engine|client_version|      date| experiment|\n",
       "+--------------------------+--------------+----------------------+------------------------------------+-----------------------+-----------------------+----------+-----------+----------+-----------+-------------+------------+------------------------------------------------------------------------------------------------------------------------+---------------+----------------------+-------+-----------+--------+-------------+--------------+----------+-----------+\n",
       "|covid_messaging_experiment|       control|           18802093142|3e1d31a3-41c2-4f22-9b77-6a67f44a269a|2020-09-14 11:21:40.177|2020-09-14 11:22:05.571|    user_0| -535397001| 596780373|18811053836|  18786493712| 18802093142|[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...|162.227.140.251|python-requests/2.24.0|   null|      false|      99|   python-sdk|         3.5.2|2020-09-14|18786493712|\n",
       "|covid_messaging_experiment|       control|           18802093142|e37700df-856c-46c9-9c6d-b771ff244c2c|2020-09-14 11:21:40.279|2020-09-14 11:22:12.287|    user_1|-1393366513| 596780373|18811053836|  18786493712| 18802093142|[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...|162.227.140.251|python-requests/2.24.0|   null|      false|      99|   python-sdk|         3.5.2|2020-09-14|18786493712|\n",
       "|covid_messaging_experiment|       control|           18802093142|c011276d-7ae0-46bd-acfb-28cdcc268545|2020-09-14 11:21:40.381|2020-09-14 11:21:59.163|    user_2|  340330538| 596780373|18811053836|  18786493712| 18802093142|[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...|162.227.140.251|python-requests/2.24.0|   null|      false|      99|   python-sdk|         3.5.2|2020-09-14|18786493712|\n",
       "+--------------------------+--------------+----------------------+------------------------------------+-----------------------+-----------------------+----------+-----------+----------+-----------+-------------+------------+------------------------------------------------------------------------------------------------------------------------+---------------+----------------------+-------+-----------+--------+-------------+--------------+----------+-----------+"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from lib import util\n",
    "\n",
    "units_dir = os.path.join(optimizely_data_dir, \"type=experiment_units\")\n",
    "\n",
    "# load experiment unit data from disk into a new Spark dataframe\n",
    "decisions = util.read_parquet_data_from_disk(\n",
    "    spark_session=spark,\n",
    "    data_path=units_dir,\n",
    "    view_name=\"experiment_units\"\n",
    ")\n",
    "\n",
    "# View a sample of the loaded experiment unit records\n",
    "spark.sql(\"SELECT * FROM experiment_units LIMIT 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll load experiment event data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>experiment_id</th><th>experiment_name</th><th>variation_id</th><th>variation_name</th><th>uuid</th><th>timestamp</th><th>process_timestamp</th><th>visitor_id</th><th>session_id</th><th>account_id</th><th>experiments</th><th>entity_id</th><th>attributes</th><th>user_ip</th><th>user_agent</th><th>referer</th><th>event_type</th><th>event_name</th><th>revenue</th><th>value</th><th>quantity</th><th>tags</th><th>revision</th><th>client_engine</th><th>client_version</th><th>date</th><th>event</th></tr>\n",
       "<tr><td>18786493712</td><td>covid_messaging_experiment</td><td>18802093142</td><td>control</td><td>315063de-5f7d-4105-ba65-88a7768d80ca</td><td>2020-09-14 11:23:50.677</td><td>2020-09-14 11:24:32.015</td><td>user_1283</td><td>1441429334</td><td>596780373</td><td>[[18803622799, 18805683213, 18809464474, false], [18811053836, 18786493712, 18802093142, false]]</td><td>18822540003</td><td>[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...</td><td>162.227.140.251</td><td>python-requests/2.24.0</td><td>null</td><td>null</td><td>homepage_view</td><td>0</td><td>null</td><td>0</td><td>[]</td><td>99</td><td>python-sdk</td><td>3.5.2</td><td>2020-09-14</td><td>homepage_view</td></tr>\n",
       "<tr><td>18786493712</td><td>covid_messaging_experiment</td><td>18818611832</td><td>message_1</td><td>4506ef78-951d-411c-9eb7-6658bf82199c</td><td>2020-09-14 11:23:50.883</td><td>2020-09-14 11:24:17.604</td><td>user_1285</td><td>-152925476</td><td>596780373</td><td>[[18803622799, 18805683213, 18774763028, false], [18811053836, 18786493712, 18818611832, false]]</td><td>18822540003</td><td>[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...</td><td>162.227.140.251</td><td>python-requests/2.24.0</td><td>null</td><td>null</td><td>homepage_view</td><td>0</td><td>null</td><td>0</td><td>[]</td><td>99</td><td>python-sdk</td><td>3.5.2</td><td>2020-09-14</td><td>homepage_view</td></tr>\n",
       "<tr><td>18786493712</td><td>covid_messaging_experiment</td><td>18817551468</td><td>message_2</td><td>2a97d911-093d-4b7f-8d4b-3f92f4b4c936</td><td>2020-09-14 11:24:03.368</td><td>2020-09-14 11:24:10.597</td><td>user_1408</td><td>-582840818</td><td>596780373</td><td>[[18803622799, 18805683213, 18809464474, false], [18811053836, 18786493712, 18817551468, false]]</td><td>18822540003</td><td>[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...</td><td>162.227.140.251</td><td>python-requests/2.24.0</td><td>null</td><td>null</td><td>homepage_view</td><td>0</td><td>null</td><td>0</td><td>[]</td><td>99</td><td>python-sdk</td><td>3.5.2</td><td>2020-09-14</td><td>homepage_view</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+--------------------------+------------+--------------+------------------------------------+-----------------------+-----------------------+----------+----------+----------+------------------------------------------------------------------------------------------------+-----------+------------------------------------------------------------------------------------------------------------------------+---------------+----------------------+-------+----------+-------------+-------+-----+--------+----+--------+-------------+--------------+----------+-------------+\n",
       "|experiment_id|           experiment_name|variation_id|variation_name|                                uuid|              timestamp|      process_timestamp|visitor_id|session_id|account_id|                                                                                     experiments|  entity_id|                                                                                                              attributes|        user_ip|            user_agent|referer|event_type|   event_name|revenue|value|quantity|tags|revision|client_engine|client_version|      date|        event|\n",
       "+-------------+--------------------------+------------+--------------+------------------------------------+-----------------------+-----------------------+----------+----------+----------+------------------------------------------------------------------------------------------------+-----------+------------------------------------------------------------------------------------------------------------------------+---------------+----------------------+-------+----------+-------------+-------+-----+--------+----+--------+-------------+--------------+----------+-------------+\n",
       "|  18786493712|covid_messaging_experiment| 18802093142|       control|315063de-5f7d-4105-ba65-88a7768d80ca|2020-09-14 11:23:50.677|2020-09-14 11:24:32.015| user_1283|1441429334| 596780373|[[18803622799, 18805683213, 18809464474, false], [18811053836, 18786493712, 18802093142, false]]|18822540003|[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...|162.227.140.251|python-requests/2.24.0|   null|      null|homepage_view|      0| null|       0|  []|      99|   python-sdk|         3.5.2|2020-09-14|homepage_view|\n",
       "|  18786493712|covid_messaging_experiment| 18818611832|     message_1|4506ef78-951d-411c-9eb7-6658bf82199c|2020-09-14 11:23:50.883|2020-09-14 11:24:17.604| user_1285|-152925476| 596780373|[[18803622799, 18805683213, 18774763028, false], [18811053836, 18786493712, 18818611832, false]]|18822540003|[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...|162.227.140.251|python-requests/2.24.0|   null|      null|homepage_view|      0| null|       0|  []|      99|   python-sdk|         3.5.2|2020-09-14|homepage_view|\n",
       "|  18786493712|covid_messaging_experiment| 18817551468|     message_2|2a97d911-093d-4b7f-8d4b-3f92f4b4c936|2020-09-14 11:24:03.368|2020-09-14 11:24:10.597| user_1408|-582840818| 596780373|[[18803622799, 18805683213, 18809464474, false], [18811053836, 18786493712, 18817551468, false]]|18822540003|[[$opt_bot_filtering, $opt_bot_filtering, custom, false], [$opt_enrich_decisions, $opt_enrich_decisions, custom, true...|162.227.140.251|python-requests/2.24.0|   null|      null|homepage_view|      0| null|       0|  []|      99|   python-sdk|         3.5.2|2020-09-14|homepage_view|\n",
       "+-------------+--------------------------+------------+--------------+------------------------------------+-----------------------+-----------------------+----------+----------+----------+------------------------------------------------------------------------------------------------+-----------+------------------------------------------------------------------------------------------------------------------------+---------------+----------------------+-------+----------+-------------+-------+-----+--------+----+--------+-------------+--------------+----------+-------------+"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oevents downloads conversion data into the type=events subdirectory\n",
    "experiment_events_dir = os.path.join(optimizely_data_dir, \"type=experiment_events\")\n",
    "\n",
    "# load experiment unit data from disk into a new Spark dataframe\n",
    "decisions = util.read_parquet_data_from_disk(\n",
    "    spark_session=spark,\n",
    "    data_path=experiment_events_dir,\n",
    "    view_name=\"experiment_events\"\n",
    ")\n",
    "\n",
    "# View a sample of the loaded experiment event records\n",
    "spark.sql(\"SELECT * FROM experiment_events LIMIT 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metric observations\n",
    "\n",
    "**Metric observations** map each **experiment unit** to a specific numerical outcome observed during an experiment.  For example, in order to measure purchase conversion rate associated with each variation in an experiment, we can map each visitor to a 0 or 1, depending on whether or not they'd made at least one purchase during the attribution window in our experiment.\n",
    "\n",
    "Unlike **experiment units** and **experiment events**, which can be computed using simple transformations,  **metric observations** are metric-dependent and can be arbitrarily complex, depending on the outcome you're trying to measure.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"img/transformations_3.png\" alt=\"Experiment Units\" style=\"width:100%; padding-left:0px\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"img/tables_3.png\" alt=\"Experiment Units\" style=\"width:100%; padding-left:0px\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by defining `add_observations` a helper function that is used to join computed observations with experiment units and append the resulting records to a global `observations` view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "observations = None\n",
    "metric_names = []\n",
    "\n",
    "def add_observations(metric_name, observations_df, units_df=None):\n",
    "    \"\"\"Add a new set of observations to the observations view\n",
    "    \n",
    "    Parameters: \n",
    "        metric_name         - A string that uniquely identifies metric for which observations are being computed,\n",
    "                              for example: \"purchase_conversion_rate\"\n",
    "        observations_df     - A spark dataframe containing the set of observations to be added.  This dataframe should\n",
    "                              contain two columns:\n",
    "                                  visitor_id\n",
    "                                  observation - numerical outcome observered for this metric\n",
    "        units_df (optional) - A spark dataframe containing the experiment units for which this metric should be\n",
    "                              computed.  This is useful if you wish to filter the units in order to analyze\n",
    "                              experiment results for a specific subsample, e.g. \"subscribed users\".  If this\n",
    "                              parameter is omitted, the full experiment_units dataframe will be used.\n",
    "    \"\"\"\n",
    "  \n",
    "    global metric_names\n",
    "    if metric_name in metric_names:\n",
    "        raise Exception(f\"Metric '{metric_name}' has already been computed.  Please choose a different name.\")\n",
    "        \n",
    "    metric_names.append(metric_name)\n",
    "\n",
    "    units_df = units_df or experiment_units\n",
    "    merged_df = units_df.join(observations_df, on=['visitor_id'], how='left') \\\n",
    "                        .withColumn(\"_observation\", F.coalesce('observation', F.lit(0))) \\\n",
    "                        .drop(\"observation\") \\\n",
    "                        .withColumnRenamed(\"_observation\", \"observation\") \\\n",
    "                        .withColumn(\"metric_name\", F.lit(metric_name))\n",
    "\n",
    "    global observations\n",
    "    if observations is None:\n",
    "        observations = merged_df\n",
    "    else:\n",
    "        observations = observations.union(merged_df)\n",
    "    observations.createOrReplaceTempView(\"observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define a set of observations by executing simple queries on our experiment events.  Each query computes a single _observation_ for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Purchase conversion rate\n",
    "\n",
    "In this query we measure for each visitor whether they made _at least one_ purchase. The resulting observation should be `1` if the visitor triggered the event in question during the _attribution window_ and `0` otherwise.  \n",
    "\n",
    "Since _any_ visitor who triggered an appropriate experiment event should be counted, we can simply select a `1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_5967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_9069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  visitor_id  observation\n",
       "0  user_5967            1\n",
       "1  user_1434            1\n",
       "2  user_3058            1\n",
       "3   user_926            1\n",
       "4  user_9069            1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Unique conversions on the \"add to cart\" event.\n",
    "metric_obs = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        visitor_id,\n",
    "        1 as observation\n",
    "    FROM\n",
    "        experiment_events\n",
    "    WHERE\n",
    "        event_name = 'purchase'\n",
    "    GROUP BY\n",
    "        visitor_id\n",
    "\"\"\")\n",
    "metric_obs.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use our `add_observations` function to perform a left outer join between `experiment_units` and our newly-computed `add_to_cart` conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_observations(\n",
    "    \"Purchase conversion rate\",\n",
    "    metric_obs,\n",
    "    experiment_units\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our observations view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>metric_name</th><th>visitor_id</th><th>experiment_name</th><th>variation_name</th><th>observation</th></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_1048</td><td>covid_messaging_experiment</td><td>message_2</td><td>0</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_1368</td><td>covid_messaging_experiment</td><td>message_2</td><td>0</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_1425</td><td>covid_messaging_experiment</td><td>message_1</td><td>0</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_1786</td><td>covid_messaging_experiment</td><td>message_2</td><td>0</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_2262</td><td>covid_messaging_experiment</td><td>control</td><td>0</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_2349</td><td>covid_messaging_experiment</td><td>control</td><td>0</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_242</td><td>covid_messaging_experiment</td><td>message_1</td><td>0</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_248</td><td>covid_messaging_experiment</td><td>message_1</td><td>0</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_2573</td><td>covid_messaging_experiment</td><td>message_1</td><td>0</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>user_2937</td><td>covid_messaging_experiment</td><td>message_1</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------------------+----------+--------------------------+--------------+-----------+\n",
       "|             metric_name|visitor_id|           experiment_name|variation_name|observation|\n",
       "+------------------------+----------+--------------------------+--------------+-----------+\n",
       "|Purchase conversion rate| user_1048|covid_messaging_experiment|     message_2|          0|\n",
       "|Purchase conversion rate| user_1368|covid_messaging_experiment|     message_2|          0|\n",
       "|Purchase conversion rate| user_1425|covid_messaging_experiment|     message_1|          0|\n",
       "|Purchase conversion rate| user_1786|covid_messaging_experiment|     message_2|          0|\n",
       "|Purchase conversion rate| user_2262|covid_messaging_experiment|       control|          0|\n",
       "|Purchase conversion rate| user_2349|covid_messaging_experiment|       control|          0|\n",
       "|Purchase conversion rate|  user_242|covid_messaging_experiment|     message_1|          0|\n",
       "|Purchase conversion rate|  user_248|covid_messaging_experiment|     message_1|          0|\n",
       "|Purchase conversion rate| user_2573|covid_messaging_experiment|     message_1|          0|\n",
       "|Purchase conversion rate| user_2937|covid_messaging_experiment|     message_1|          0|\n",
       "+------------------------+----------+--------------------------+--------------+-----------+"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        metric_name,\n",
    "        visitor_id, \n",
    "        experiment_name, \n",
    "        variation_name, \n",
    "        observation \n",
    "    FROM \n",
    "        observations \n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric observations can be used to compute a variety of useful statistics.  Let's compute the value of our `purchase` conversion rate metric for all of the visitors in our experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>metric_name</th><th>experiment_name</th><th>unit_count</th><th>sum(observation)</th><th>metric_value</th></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>covid_messaging_experiment</td><td>10000</td><td>555</td><td>0.05550000000000000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------------------+--------------------------+----------+----------------+-------------------+\n",
       "|             metric_name|           experiment_name|unit_count|sum(observation)|       metric_value|\n",
       "+------------------------+--------------------------+----------+----------------+-------------------+\n",
       "|Purchase conversion rate|covid_messaging_experiment|     10000|             555|0.05550000000000000|\n",
       "+------------------------+--------------------------+----------+----------------+-------------------+"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        metric_name,\n",
    "        experiment_name,\n",
    "        count(1) as unit_count,\n",
    "        sum(observation),\n",
    "        sum(observation) / (1.0 * count(1)) as metric_value\n",
    "    FROM\n",
    "        observations\n",
    "    WHERE\n",
    "        metric_name = \"Purchase conversion rate\"\n",
    "    GROUP BY\n",
    "        metric_name,\n",
    "        experiment_name\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the `purchase` conversion rate broken down by experiment variation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>metric_name</th><th>experiment_name</th><th>variation_name</th><th>unit_count</th><th>sum(observation)</th><th>metric_value</th></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>covid_messaging_experiment</td><td>message_1</td><td>3367</td><td>169</td><td>0.05019305019305019</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>covid_messaging_experiment</td><td>control</td><td>3304</td><td>163</td><td>0.04933414043583535</td></tr>\n",
       "<tr><td>Purchase conversion rate</td><td>covid_messaging_experiment</td><td>message_2</td><td>3329</td><td>223</td><td>0.06698708320817062</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------------------+--------------------------+--------------+----------+----------------+-------------------+\n",
       "|             metric_name|           experiment_name|variation_name|unit_count|sum(observation)|       metric_value|\n",
       "+------------------------+--------------------------+--------------+----------+----------------+-------------------+\n",
       "|Purchase conversion rate|covid_messaging_experiment|     message_1|      3367|             169|0.05019305019305019|\n",
       "|Purchase conversion rate|covid_messaging_experiment|       control|      3304|             163|0.04933414043583535|\n",
       "|Purchase conversion rate|covid_messaging_experiment|     message_2|      3329|             223|0.06698708320817062|\n",
       "+------------------------+--------------------------+--------------+----------+----------------+-------------------+"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        metric_name,\n",
    "        experiment_name,\n",
    "        variation_name,\n",
    "        count(1) as unit_count,\n",
    "        sum(observation),\n",
    "        sum(observation) / (1.0 * count(1)) as metric_value\n",
    "    FROM\n",
    "        observations\n",
    "    WHERE\n",
    "        metric_name = \"Purchase conversion rate\"\n",
    "    GROUP BY\n",
    "        metric_name,\n",
    "        experiment_name,\n",
    "        variation_name\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Items added to cart per visitor\n",
    "\n",
    "In this query we compute the number of unique conversions on a particular event for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique conversions on the \"add_to_cart\" event.\n",
    "add_observations(\n",
    "    \"Items added to cart\",\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            visitor_id,\n",
    "            count(1) as observation\n",
    "        FROM\n",
    "            experiment_events\n",
    "        WHERE\n",
    "            event_name = \"add_to_cart\"\n",
    "        GROUP BY\n",
    "            visitor_id\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect our observations by counting the units and summing up the observations we've computed for each experiment in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>metric_name</th><th>experiment_name</th><th>variation_name</th><th>visitor_id</th><th>observation</th></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>message_2</td><td>user_1048</td><td>0</td></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>message_2</td><td>user_1368</td><td>0</td></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>message_1</td><td>user_1425</td><td>0</td></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>message_2</td><td>user_1786</td><td>0</td></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>control</td><td>user_2262</td><td>0</td></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>control</td><td>user_2349</td><td>0</td></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>message_1</td><td>user_242</td><td>0</td></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>message_1</td><td>user_248</td><td>0</td></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>message_1</td><td>user_2573</td><td>0</td></tr>\n",
       "<tr><td>Items added to cart</td><td>covid_messaging_experiment</td><td>message_1</td><td>user_2937</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------+--------------------------+--------------+----------+-----------+\n",
       "|        metric_name|           experiment_name|variation_name|visitor_id|observation|\n",
       "+-------------------+--------------------------+--------------+----------+-----------+\n",
       "|Items added to cart|covid_messaging_experiment|     message_2| user_1048|          0|\n",
       "|Items added to cart|covid_messaging_experiment|     message_2| user_1368|          0|\n",
       "|Items added to cart|covid_messaging_experiment|     message_1| user_1425|          0|\n",
       "|Items added to cart|covid_messaging_experiment|     message_2| user_1786|          0|\n",
       "|Items added to cart|covid_messaging_experiment|       control| user_2262|          0|\n",
       "|Items added to cart|covid_messaging_experiment|       control| user_2349|          0|\n",
       "|Items added to cart|covid_messaging_experiment|     message_1|  user_242|          0|\n",
       "|Items added to cart|covid_messaging_experiment|     message_1|  user_248|          0|\n",
       "|Items added to cart|covid_messaging_experiment|     message_1| user_2573|          0|\n",
       "|Items added to cart|covid_messaging_experiment|     message_1| user_2937|          0|\n",
       "+-------------------+--------------------------+--------------+----------+-----------+"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        metric_name, \n",
    "        experiment_name, \n",
    "        variation_name,\n",
    "        visitor_id, \n",
    "        observation \n",
    "    FROM \n",
    "        observations\n",
    "    WHERE\n",
    "        metric_name = \"Items added to cart\"\n",
    "    LIMIT 10\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Revenue from electronics purchases\n",
    "\n",
    "In this query we compute the total revenue associated with electronics purchases made by our experiment subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_observations(\n",
    "    \"Electronics revenue per visitor\",\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            visitor_id,\n",
    "            sum(revenue) as observation\n",
    "        FROM \n",
    "            experiment_events\n",
    "            LATERAL VIEW explode(tags) t\n",
    "        WHERE\n",
    "            t.key = \"category\" AND \n",
    "            t.value = \"electronics\" AND\n",
    "            event_name = \"purchase\"\n",
    "        GROUP BY\n",
    "            visitor_id\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's examine our observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>metric_name</th><th>experiment_name</th><th>variation_id</th><th>visitor_id</th><th>observation</th></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18817551468</td><td>user_1048</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18817551468</td><td>user_1368</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18818611832</td><td>user_1425</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18817551468</td><td>user_1786</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18802093142</td><td>user_2262</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18802093142</td><td>user_2349</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18818611832</td><td>user_242</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18818611832</td><td>user_248</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18818611832</td><td>user_2573</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18818611832</td><td>user_2937</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18802093142</td><td>user_2952</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18818611832</td><td>user_3547</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18802093142</td><td>user_3649</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18817551468</td><td>user_4041</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18817551468</td><td>user_424</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18818611832</td><td>user_4537</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18817551468</td><td>user_4562</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18802093142</td><td>user_4746</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18818611832</td><td>user_4761</td><td>0</td></tr>\n",
       "<tr><td>Electronics revenue per visitor</td><td>covid_messaging_experiment</td><td>18818611832</td><td>user_5001</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------------------+--------------------------+------------+----------+-----------+\n",
       "|                    metric_name|           experiment_name|variation_id|visitor_id|observation|\n",
       "+-------------------------------+--------------------------+------------+----------+-----------+\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18817551468| user_1048|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18817551468| user_1368|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18818611832| user_1425|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18817551468| user_1786|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18802093142| user_2262|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18802093142| user_2349|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18818611832|  user_242|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18818611832|  user_248|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18818611832| user_2573|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18818611832| user_2937|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18802093142| user_2952|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18818611832| user_3547|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18802093142| user_3649|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18817551468| user_4041|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18817551468|  user_424|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18818611832| user_4537|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18817551468| user_4562|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18802093142| user_4746|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18818611832| user_4761|          0|\n",
       "|Electronics revenue per visitor|covid_messaging_experiment| 18818611832| user_5001|          0|\n",
       "+-------------------------------+--------------------------+------------+----------+-----------+"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        metric_name, \n",
    "        experiment_name, \n",
    "        variation_id, \n",
    "        visitor_id, \n",
    "        observation \n",
    "    FROM \n",
    "        observations\n",
    "    WHERE\n",
    "        metric_name = \"Electronics revenue per visitor\"\n",
    "    LIMIT 20\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing our datasets to disk\n",
    "\n",
    "We'll write our experiment units and events datasets to disk so that they may be used for other analysis tasks.  Experiment unit data is partitioned by `experiment_id` and experiment event data is partitioned by `event_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_WRITING_OUTPUT_DATA_TO_DISK: \n",
    "    \n",
    "    observations_output_dir = os.path.join(optimizely_data_dir, \"type=metric_observations\")\n",
    "    \n",
    "    spark.sql(\"SELECT * FROM observations\") \\\n",
    "        .coalesce(1) \\\n",
    "        .write.mode('overwrite') \\\n",
    "        .partitionBy(\"experiment_id\", \"metric_name\") \\\n",
    "        .parquet(observations_output_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Optimizely Labs Environment)",
   "language": "python",
   "name": "optimizelylabs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
